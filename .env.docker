# Docker Environment Configuration for llm-bawt
# Copy this file to .env and fill in your values.
# This single .env is used for docker-compose substitution and app runtime config.

# Build
WITH_CUDA=true
CUDA_ARCHS=120

# Ports (host -> container)
MCP_PORT=8001
SERVICE_PORT=8642

# Paths
MODELS_PATH=./models
LLM_BAWT_MODEL_CACHE_DIR=~/.cache/llm-bawt/models
HF_HOME=~/.cache/huggingface

# Core
LLM_BAWT_DEFAULT_BOT=nova
LLM_BAWT_DEFAULT_MODEL_ALIAS=gpt-5.2-chat-latest
LLM_BAWT_DEFAULT_USER=user
LLM_BAWT_USE_SERVICE=true
LLM_BAWT_SERVICE_HOST=0.0.0.0
LLM_BAWT_SERVICE_PORT=8642
LLM_BAWT_MEMORY_SERVER_URL=http://127.0.0.1:8001
LLM_BAWT_LOG_DIR=.logs
LLM_BAWT_LOG_PREFIX=docker
LLM_BAWT_DEBUG_TURN_LOG=false
LLM_BAWT_HISTORY_DURATION=1800
LLM_BAWT_MAX_TOKENS=4096

# Llama.cpp (optional)
LLM_BAWT_LLAMA_CPP_N_CTX=8192
LLM_BAWT_LLAMA_CPP_N_GPU_LAYERS=-1
LLM_BAWT_LLAMA_CPP_N_BATCH=1024
LLM_BAWT_LLAMA_CPP_FLASH_ATTN=true

# PostgreSQL
LLM_BAWT_POSTGRES_HOST=localhost
LLM_BAWT_POSTGRES_PORT=5432
LLM_BAWT_POSTGRES_USER=llm_bawt
LLM_BAWT_POSTGRES_PASSWORD=
LLM_BAWT_POSTGRES_DATABASE=llm_bawt

# xAI (Grok)
LLM_BAWT_XAI_API_KEY=

# Search
LLM_BAWT_SEARCH_PROVIDER=duckduckgo
LLM_BAWT_TAVILY_API_KEY=
LLM_BAWT_BRAVE_API_KEY=

# Providers
OPENAI_API_KEY=
XAI_API_KEY=
ANTHROPIC_API_KEY=
HF_TOKEN=

# Nextcloud Talk (optional)
LLM_BAWT_NEXTCLOUD_URL=https://nextcloud.example.com
LLM_BAWT_NEXTCLOUD_BOT_SECRET=
LLM_BAWT_TALK_PROVISIONER_URL=http://localhost:8790
LLM_BAWT_TALK_PROVISIONER_TOKEN=

# Transformers / HF behavior
HF_HUB_DISABLE_PROGRESS_BARS=1
TRANSFORMERS_NO_ADVISORY_WARNINGS=1
TRANSFORMERS_VERBOSITY=error
TOKENIZERS_PARALLELISM=false
